{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow_addons as tfa\n",
    "import decimal\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from tensorflow.keras import activations\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>release_date</th>\n",
       "      <th>restrict</th>\n",
       "      <th>orig_title</th>\n",
       "      <th>kinopoisk_id</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>emotions</th>\n",
       "      <th>Place of act</th>\n",
       "      <th>Qualities</th>\n",
       "      <th>Time of act</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Audience</th>\n",
       "      <th>Mood</th>\n",
       "      <th>Subgenre</th>\n",
       "      <th>About</th>\n",
       "      <th>Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5816.0</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Phil</td>\n",
       "      <td>960568</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.86</td>\n",
       "      <td>Фил – стоматолог, страдающий от депрессии. Его...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Драмы,Зарубежные,Комедии}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neutral': 0.5312193632125854, 'negative': 0....</td>\n",
       "      <td>['США']</td>\n",
       "      <td>['дебютный']</td>\n",
       "      <td>['21-й век', 'новейшее время']</td>\n",
       "      <td>['оригинального сценария']</td>\n",
       "      <td>['для молодёжи', 'для взрослых']</td>\n",
       "      <td>['грустный', 'депрессивный', 'трогательный']</td>\n",
       "      <td>['Драмы', 'Комедийные']</td>\n",
       "      <td>['преследования', 'самозванцы', 'расследование...</td>\n",
       "      <td>['развлекательные', 'психологический']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5123.0</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>1126022</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Старая женщина начинает рассказывать легенду о...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Зарубежные,Триллеры,Ужасы}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'negative': 0.4688006341457367, 'skip': 0.392...</td>\n",
       "      <td>['не определено']</td>\n",
       "      <td>['зрелищные', 'жанровый', 'неожиданный финал']</td>\n",
       "      <td>['не определено']</td>\n",
       "      <td>['эпоса и легенд', 'оригинального сценария']</td>\n",
       "      <td>['для взрослых', 'для мужчин', 'для подготовле...</td>\n",
       "      <td>['трагичные', 'мрачные', 'шокирующие', 'захват...</td>\n",
       "      <td>['ужасы', 'триллер']</td>\n",
       "      <td>['преследования', 'страхи', 'дети', 'молодежь'...</td>\n",
       "      <td>['развлекательные']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4667.0</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Wake Up</td>\n",
       "      <td>1069713</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Врач-психиатр исследует дневник девушки, котор...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Боевики,Зарубежные,Криминал,Триллеры,Ужасы}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'positive': 0.3140605390071869, 'negative': 0...</td>\n",
       "      <td>['не определено']</td>\n",
       "      <td>['жанровый', 'дебютный']</td>\n",
       "      <td>['новейшее время']</td>\n",
       "      <td>['оригинального сценария']</td>\n",
       "      <td>['для взрослых', 'для подготовленного зрителя'...</td>\n",
       "      <td>['захватывающие', 'жестокие', 'напряженные', '...</td>\n",
       "      <td>['Драмы', 'Боевики', 'триллер']</td>\n",
       "      <td>['психотерапевты', 'кровь', 'тайна смерти', 'п...</td>\n",
       "      <td>['психологический', 'развлекательные']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6148.0</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>The Kitchen</td>\n",
       "      <td>1117988</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>Смотрите в 4К! Три жены ирландских гангстеров,...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Боевики,Драмы,Зарубежные,Криминал,По комиксам}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neutral': 0.4765896201133728, 'negative': 0....</td>\n",
       "      <td>['большой город', 'США']</td>\n",
       "      <td>['жанровый', 'остросюжетные']</td>\n",
       "      <td>['20-й век']</td>\n",
       "      <td>['комиксов']</td>\n",
       "      <td>['для мужчин', 'для женщин', 'для взрослых']</td>\n",
       "      <td>['захватывающие', 'авантюрный', 'жестокие', 'н...</td>\n",
       "      <td>['Боевики', 'Драмы', 'криминальные']</td>\n",
       "      <td>['враги или вражда', 'женщины', 'антигерои', '...</td>\n",
       "      <td>['авантюрные', 'гангстерская']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6013.0</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Pokémon Detective Pikachu</td>\n",
       "      <td>994864</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.56</td>\n",
       "      <td>Смотрите в 4K! Элитный детектив Пикачу отправл...</td>\n",
       "      <td>{Для детей,Фильмы}</td>\n",
       "      <td>{Детективы,Зарубежные,Комедии,Семейные,Фильмы,...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neutral': 0.4532718360424042, 'negative': 0....</td>\n",
       "      <td>['вымышленная страна (город)', 'большой город']</td>\n",
       "      <td>['частично анимационный', 'зрелищные', 'кассов...</td>\n",
       "      <td>['21-й век']</td>\n",
       "      <td>['оригинального сценария', 'сериалов']</td>\n",
       "      <td>['для детей 13-16 лет', '9 лет', '8 лет', '7-1...</td>\n",
       "      <td>['авантюрный', 'захватывающие', 'динамичный', ...</td>\n",
       "      <td>['детские', 'Приключенческие', 'Фантастические...</td>\n",
       "      <td>['притяжение противоположностей', 'риск', 'пре...</td>\n",
       "      <td>['развлекательные', 'образовательный']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration release_date  restrict                 orig_title  kinopoisk_id  \\\n",
       "0    5816.0   2019-04-05      18.0                       Phil        960568   \n",
       "1    5123.0   2019-04-02      18.0                Tooth Fairy       1126022   \n",
       "2    4667.0   2019-01-19      16.0                    Wake Up       1069713   \n",
       "3    6148.0   2019-08-09      16.0                The Kitchen       1117988   \n",
       "4    6013.0   2019-05-02      12.0  Pokémon Detective Pikachu        994864   \n",
       "\n",
       "   imdb_rating  kinopoisk_rating  \\\n",
       "0          5.4              5.86   \n",
       "1          2.2              0.00   \n",
       "2          2.9              0.00   \n",
       "3          5.5              5.50   \n",
       "4          6.6              6.56   \n",
       "\n",
       "                                            synopsis          categories  \\\n",
       "0  Фил – стоматолог, страдающий от депрессии. Его...            {Фильмы}   \n",
       "1  Старая женщина начинает рассказывать легенду о...            {Фильмы}   \n",
       "2  Врач-психиатр исследует дневник девушки, котор...            {Фильмы}   \n",
       "3  Смотрите в 4К! Три жены ирландских гангстеров,...            {Фильмы}   \n",
       "4  Смотрите в 4K! Элитный детектив Пикачу отправл...  {Для детей,Фильмы}   \n",
       "\n",
       "                                              genres  ...  \\\n",
       "0                         {Драмы,Зарубежные,Комедии}  ...   \n",
       "1                        {Зарубежные,Триллеры,Ужасы}  ...   \n",
       "2       {Боевики,Зарубежные,Криминал,Триллеры,Ужасы}  ...   \n",
       "3    {Боевики,Драмы,Зарубежные,Криминал,По комиксам}  ...   \n",
       "4  {Детективы,Зарубежные,Комедии,Семейные,Фильмы,...  ...   \n",
       "\n",
       "                                            emotions  \\\n",
       "0  {'neutral': 0.5312193632125854, 'negative': 0....   \n",
       "1  {'negative': 0.4688006341457367, 'skip': 0.392...   \n",
       "2  {'positive': 0.3140605390071869, 'negative': 0...   \n",
       "3  {'neutral': 0.4765896201133728, 'negative': 0....   \n",
       "4  {'neutral': 0.4532718360424042, 'negative': 0....   \n",
       "\n",
       "                                      Place of act  \\\n",
       "0                                          ['США']   \n",
       "1                                ['не определено']   \n",
       "2                                ['не определено']   \n",
       "3                         ['большой город', 'США']   \n",
       "4  ['вымышленная страна (город)', 'большой город']   \n",
       "\n",
       "                                           Qualities  \\\n",
       "0                                       ['дебютный']   \n",
       "1     ['зрелищные', 'жанровый', 'неожиданный финал']   \n",
       "2                           ['жанровый', 'дебютный']   \n",
       "3                      ['жанровый', 'остросюжетные']   \n",
       "4  ['частично анимационный', 'зрелищные', 'кассов...   \n",
       "\n",
       "                      Time of act  \\\n",
       "0  ['21-й век', 'новейшее время']   \n",
       "1               ['не определено']   \n",
       "2              ['новейшее время']   \n",
       "3                    ['20-й век']   \n",
       "4                    ['21-й век']   \n",
       "\n",
       "                                       Based on  \\\n",
       "0                    ['оригинального сценария']   \n",
       "1  ['эпоса и легенд', 'оригинального сценария']   \n",
       "2                    ['оригинального сценария']   \n",
       "3                                  ['комиксов']   \n",
       "4        ['оригинального сценария', 'сериалов']   \n",
       "\n",
       "                                            Audience  \\\n",
       "0                   ['для молодёжи', 'для взрослых']   \n",
       "1  ['для взрослых', 'для мужчин', 'для подготовле...   \n",
       "2  ['для взрослых', 'для подготовленного зрителя'...   \n",
       "3       ['для мужчин', 'для женщин', 'для взрослых']   \n",
       "4  ['для детей 13-16 лет', '9 лет', '8 лет', '7-1...   \n",
       "\n",
       "                                                Mood  \\\n",
       "0       ['грустный', 'депрессивный', 'трогательный']   \n",
       "1  ['трагичные', 'мрачные', 'шокирующие', 'захват...   \n",
       "2  ['захватывающие', 'жестокие', 'напряженные', '...   \n",
       "3  ['захватывающие', 'авантюрный', 'жестокие', 'н...   \n",
       "4  ['авантюрный', 'захватывающие', 'динамичный', ...   \n",
       "\n",
       "                                            Subgenre  \\\n",
       "0                            ['Драмы', 'Комедийные']   \n",
       "1                               ['ужасы', 'триллер']   \n",
       "2                    ['Драмы', 'Боевики', 'триллер']   \n",
       "3               ['Боевики', 'Драмы', 'криминальные']   \n",
       "4  ['детские', 'Приключенческие', 'Фантастические...   \n",
       "\n",
       "                                               About  \\\n",
       "0  ['преследования', 'самозванцы', 'расследование...   \n",
       "1  ['преследования', 'страхи', 'дети', 'молодежь'...   \n",
       "2  ['психотерапевты', 'кровь', 'тайна смерти', 'п...   \n",
       "3  ['враги или вражда', 'женщины', 'антигерои', '...   \n",
       "4  ['притяжение противоположностей', 'риск', 'пре...   \n",
       "\n",
       "                                    Theme  \n",
       "0  ['развлекательные', 'психологический']  \n",
       "1                     ['развлекательные']  \n",
       "2  ['психологический', 'развлекательные']  \n",
       "3          ['авантюрные', 'гангстерская']  \n",
       "4  ['развлекательные', 'образовательный']  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trailers_csv = \"/Volumes/Seagate/natasha-diploma/trailers.csv\"\n",
    "trailers_df = pd.read_csv(trailers_csv, index_col=None, header=0)\n",
    "trailers_df.drop(trailers_df.columns[trailers_df.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)\n",
    "display(trailers_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>403a42b604f504069c41d39c5a4fc2</td>\n",
       "      <td>23ee5640ec588ffaa78afa3268b04a</td>\n",
       "      <td>5b150a1cae009459493bd0fe5c7b3e</td>\n",
       "      <td>e291f8ae1de4a38c71027e9c91d51c</td>\n",
       "      <td>34cfd44ad5cc2d63441ebf437eccb5</td>\n",
       "      <td>02fbcf93a730c9c9d5e65aef41c67e</td>\n",
       "      <td>26b3f811a6b9ed75d3cc5198105fa4</td>\n",
       "      <td>6fcff414343456465369b05f6851eb</td>\n",
       "      <td>e2f15819192cded77ed1825a129c0c</td>\n",
       "      <td>41b772a5b18bc724562bfb60f4f3ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5b2dd3ed41aabb5733c7cfffff0bc</td>\n",
       "      <td>25e573b81ab69d6cf700a51281fc2a</td>\n",
       "      <td>49c58f679f72e0f02b97bdeee1a1bb</td>\n",
       "      <td>c0be492c14bcec5ab3dfd34d95d6f5</td>\n",
       "      <td>b2274b9b4c8c4dc2f79d417ddd71e5</td>\n",
       "      <td>7fd08607f52b89a753437eee177e32</td>\n",
       "      <td>25d41576f3529994c878a5d15f6dc7</td>\n",
       "      <td>ece16e15b2286f8287e8935f12b6c2</td>\n",
       "      <td>806c0ed32e135afb8db4f3aad71acf</td>\n",
       "      <td>f10b4adf1c732b6b260791fb24f430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80870ec50515107ba7034ab758cebe</td>\n",
       "      <td>cd522afebcf91625c3cd811f3fb6e2</td>\n",
       "      <td>061a59839837a123a916a70947f075</td>\n",
       "      <td>07e873c5aac8ffaf97897fbd0dfbf6</td>\n",
       "      <td>60fb638ff7ab469be8637111fdc837</td>\n",
       "      <td>d49c4a9b748b9c7abb9d98cdecebef</td>\n",
       "      <td>b0b062dc25c4dada316183941b100c</td>\n",
       "      <td>c7f809aab571e9acdf799a78c5ef61</td>\n",
       "      <td>67c38de267396951227897efc503e1</td>\n",
       "      <td>7b457a5d30f3cb01b6998390ec7abf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d66440e7524c0a8b9b206fbb7295ba</td>\n",
       "      <td>046f93c91d0befd4625f00e07eb473</td>\n",
       "      <td>199cf6d89a2f06fc552ebf86105d7d</td>\n",
       "      <td>2adfc14bbc0fba5b5d616d6fcfe3de</td>\n",
       "      <td>a458a5a362af9a7774780eb4e25365</td>\n",
       "      <td>88bbc5912f946b1fb77fdeaa3f5d4a</td>\n",
       "      <td>6d0bb6959972ac92c10d7445982a94</td>\n",
       "      <td>274869b912b256df69b9e7c5c0cb11</td>\n",
       "      <td>2c5bf20534b80ee47bed9a90b405a0</td>\n",
       "      <td>f456635bb3d2567a3a61133fa9dd89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231b80c884b2f1390e17f09a187889</td>\n",
       "      <td>bd6707bb04cfb8880a5f783c85be20</td>\n",
       "      <td>bbd5df907c099d2cc2b5285b08038e</td>\n",
       "      <td>514f3ee1f00df05dc3900251972245</td>\n",
       "      <td>961c336b0c2fa04c883c639dfee1ba</td>\n",
       "      <td>d6159553e41857fe23df9d3e746284</td>\n",
       "      <td>d2cd45a49d53702df403cffddd53e6</td>\n",
       "      <td>c0314a446fbef65ce9626b037a70da</td>\n",
       "      <td>d6e8f6d21631149a90ac940d3ee227</td>\n",
       "      <td>e762f208419b7449c0731037262bb3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>91e8db1b91acc7bf903bf670461db3</td>\n",
       "      <td>f65c8906c07b627a760a0671de7144</td>\n",
       "      <td>26ba677f7ff11ac529f5f69c54cb0b</td>\n",
       "      <td>be6360babdb2e5910c5bc6f4f04f0d</td>\n",
       "      <td>705c23ed5ae1bc8824fc955b82094b</td>\n",
       "      <td>74733260a8a5143b2eb20c4a62940a</td>\n",
       "      <td>afed0e34e5af6958fef610a0ac5565</td>\n",
       "      <td>0a49f9b4576a63be41cb96908eba5e</td>\n",
       "      <td>baec94926106f54090568b653e84b4</td>\n",
       "      <td>8a2b5f96cc30660b28636fbe2664d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>c718bcdf6240802ba7123a7a631199</td>\n",
       "      <td>5e62a64d4f0d6ca3fce397267bf9f3</td>\n",
       "      <td>c5d40f1adeb446df77e65815da405d</td>\n",
       "      <td>bbf4b4a3db602ab9b88845114f7244</td>\n",
       "      <td>0f462e6bbd719e012902d8814d0e35</td>\n",
       "      <td>e5bca888fec7f8c0116db0002a7077</td>\n",
       "      <td>8a2483e11828332a9e2fc8659ae38f</td>\n",
       "      <td>bb59c82aeb5e44eb5735d5a1c016b8</td>\n",
       "      <td>8d3877a1b26b10642d125ec4fc4c9b</td>\n",
       "      <td>ae90166aa81ab2bf878dace61a5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ee78a3aae1a69f2e4b82f26d41d594</td>\n",
       "      <td>11fe2dd4cccaf0567c878e19e1811a</td>\n",
       "      <td>aab18e84a97780bafb188fd33cb2a9</td>\n",
       "      <td>838cb9d91dd080147bcc18982bcdbb</td>\n",
       "      <td>972821d03656142f33707487f51b66</td>\n",
       "      <td>d6d45793f5b093e8bdf3d8ae4952b6</td>\n",
       "      <td>28731720ee3330b7107cec47168b8c</td>\n",
       "      <td>dad45a9302ad916f6901b86a744cdd</td>\n",
       "      <td>644bf6d0bdf6c9cddf71f5ab4cf7d4</td>\n",
       "      <td>4774caaf01df3d5d982e0cb77b1a13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>b0b062dc25c4dada316183941b100c</td>\n",
       "      <td>80870ec50515107ba7034ab758cebe</td>\n",
       "      <td>d49c4a9b748b9c7abb9d98cdecebef</td>\n",
       "      <td>67c38de267396951227897efc503e1</td>\n",
       "      <td>7b457a5d30f3cb01b6998390ec7abf</td>\n",
       "      <td>67f32aff5488778cb4bbb6b21acc7d</td>\n",
       "      <td>3d558c3e37ccb70937b171aeb67bbb</td>\n",
       "      <td>97474799458a67e30a70f66407420b</td>\n",
       "      <td>0dbe493275a25285829b979316d566</td>\n",
       "      <td>ba54f9d576e93f2b0cf4622a92310f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>02a7f8e9b88ca2a74c6637332b0998</td>\n",
       "      <td>c06fea4a59b3cc8a188a7a83bb2f61</td>\n",
       "      <td>d579d54561bf36f67f4d1dea329f1d</td>\n",
       "      <td>5ccf8f0bf03df5bf674c2aa36e7fe6</td>\n",
       "      <td>31f08ef4a727a8943644261454f1fa</td>\n",
       "      <td>b5cace1f414bee46d0441934d18bf9</td>\n",
       "      <td>16eb6fb9aee97cb7f6cd83a4ec5608</td>\n",
       "      <td>4d9b46f08e9c1fcf08ecbc5c714098</td>\n",
       "      <td>8a2483e11828332a9e2fc8659ae38f</td>\n",
       "      <td>ae90166aa81ab2bf878dace61a5620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0                               1  \\\n",
       "0    403a42b604f504069c41d39c5a4fc2  23ee5640ec588ffaa78afa3268b04a   \n",
       "1    a5b2dd3ed41aabb5733c7cfffff0bc  25e573b81ab69d6cf700a51281fc2a   \n",
       "2    80870ec50515107ba7034ab758cebe  cd522afebcf91625c3cd811f3fb6e2   \n",
       "3    d66440e7524c0a8b9b206fbb7295ba  046f93c91d0befd4625f00e07eb473   \n",
       "4    231b80c884b2f1390e17f09a187889  bd6707bb04cfb8880a5f783c85be20   \n",
       "..                              ...                             ...   \n",
       "196  91e8db1b91acc7bf903bf670461db3  f65c8906c07b627a760a0671de7144   \n",
       "197  c718bcdf6240802ba7123a7a631199  5e62a64d4f0d6ca3fce397267bf9f3   \n",
       "198  ee78a3aae1a69f2e4b82f26d41d594  11fe2dd4cccaf0567c878e19e1811a   \n",
       "199  b0b062dc25c4dada316183941b100c  80870ec50515107ba7034ab758cebe   \n",
       "200  02a7f8e9b88ca2a74c6637332b0998  c06fea4a59b3cc8a188a7a83bb2f61   \n",
       "\n",
       "                                  2                               3  \\\n",
       "0    5b150a1cae009459493bd0fe5c7b3e  e291f8ae1de4a38c71027e9c91d51c   \n",
       "1    49c58f679f72e0f02b97bdeee1a1bb  c0be492c14bcec5ab3dfd34d95d6f5   \n",
       "2    061a59839837a123a916a70947f075  07e873c5aac8ffaf97897fbd0dfbf6   \n",
       "3    199cf6d89a2f06fc552ebf86105d7d  2adfc14bbc0fba5b5d616d6fcfe3de   \n",
       "4    bbd5df907c099d2cc2b5285b08038e  514f3ee1f00df05dc3900251972245   \n",
       "..                              ...                             ...   \n",
       "196  26ba677f7ff11ac529f5f69c54cb0b  be6360babdb2e5910c5bc6f4f04f0d   \n",
       "197  c5d40f1adeb446df77e65815da405d  bbf4b4a3db602ab9b88845114f7244   \n",
       "198  aab18e84a97780bafb188fd33cb2a9  838cb9d91dd080147bcc18982bcdbb   \n",
       "199  d49c4a9b748b9c7abb9d98cdecebef  67c38de267396951227897efc503e1   \n",
       "200  d579d54561bf36f67f4d1dea329f1d  5ccf8f0bf03df5bf674c2aa36e7fe6   \n",
       "\n",
       "                                  4                               5  \\\n",
       "0    34cfd44ad5cc2d63441ebf437eccb5  02fbcf93a730c9c9d5e65aef41c67e   \n",
       "1    b2274b9b4c8c4dc2f79d417ddd71e5  7fd08607f52b89a753437eee177e32   \n",
       "2    60fb638ff7ab469be8637111fdc837  d49c4a9b748b9c7abb9d98cdecebef   \n",
       "3    a458a5a362af9a7774780eb4e25365  88bbc5912f946b1fb77fdeaa3f5d4a   \n",
       "4    961c336b0c2fa04c883c639dfee1ba  d6159553e41857fe23df9d3e746284   \n",
       "..                              ...                             ...   \n",
       "196  705c23ed5ae1bc8824fc955b82094b  74733260a8a5143b2eb20c4a62940a   \n",
       "197  0f462e6bbd719e012902d8814d0e35  e5bca888fec7f8c0116db0002a7077   \n",
       "198  972821d03656142f33707487f51b66  d6d45793f5b093e8bdf3d8ae4952b6   \n",
       "199  7b457a5d30f3cb01b6998390ec7abf  67f32aff5488778cb4bbb6b21acc7d   \n",
       "200  31f08ef4a727a8943644261454f1fa  b5cace1f414bee46d0441934d18bf9   \n",
       "\n",
       "                                  6                               7  \\\n",
       "0    26b3f811a6b9ed75d3cc5198105fa4  6fcff414343456465369b05f6851eb   \n",
       "1    25d41576f3529994c878a5d15f6dc7  ece16e15b2286f8287e8935f12b6c2   \n",
       "2    b0b062dc25c4dada316183941b100c  c7f809aab571e9acdf799a78c5ef61   \n",
       "3    6d0bb6959972ac92c10d7445982a94  274869b912b256df69b9e7c5c0cb11   \n",
       "4    d2cd45a49d53702df403cffddd53e6  c0314a446fbef65ce9626b037a70da   \n",
       "..                              ...                             ...   \n",
       "196  afed0e34e5af6958fef610a0ac5565  0a49f9b4576a63be41cb96908eba5e   \n",
       "197  8a2483e11828332a9e2fc8659ae38f  bb59c82aeb5e44eb5735d5a1c016b8   \n",
       "198  28731720ee3330b7107cec47168b8c  dad45a9302ad916f6901b86a744cdd   \n",
       "199  3d558c3e37ccb70937b171aeb67bbb  97474799458a67e30a70f66407420b   \n",
       "200  16eb6fb9aee97cb7f6cd83a4ec5608  4d9b46f08e9c1fcf08ecbc5c714098   \n",
       "\n",
       "                                  8                               9  \n",
       "0    e2f15819192cded77ed1825a129c0c  41b772a5b18bc724562bfb60f4f3ac  \n",
       "1    806c0ed32e135afb8db4f3aad71acf  f10b4adf1c732b6b260791fb24f430  \n",
       "2    67c38de267396951227897efc503e1  7b457a5d30f3cb01b6998390ec7abf  \n",
       "3    2c5bf20534b80ee47bed9a90b405a0  f456635bb3d2567a3a61133fa9dd89  \n",
       "4    d6e8f6d21631149a90ac940d3ee227  e762f208419b7449c0731037262bb3  \n",
       "..                              ...                             ...  \n",
       "196  baec94926106f54090568b653e84b4  8a2b5f96cc30660b28636fbe2664d5  \n",
       "197  8d3877a1b26b10642d125ec4fc4c9b  ae90166aa81ab2bf878dace61a5620  \n",
       "198  644bf6d0bdf6c9cddf71f5ab4cf7d4  4774caaf01df3d5d982e0cb77b1a13  \n",
       "199  0dbe493275a25285829b979316d566  ba54f9d576e93f2b0cf4622a92310f  \n",
       "200  8a2483e11828332a9e2fc8659ae38f  ae90166aa81ab2bf878dace61a5620  \n",
       "\n",
       "[201 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessions_csv = \"/Volumes/Seagate/natasha-diploma/sessions.csv\"\n",
    "sessions_df = pd.read_csv(sessions_csv, index_col=None, header=0)\n",
    "sessions_df.drop(sessions_df.columns[sessions_df.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)\n",
    "display(sessions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "(2010,)\n"
     ]
    }
   ],
   "source": [
    "movies_id = sessions_df.to_numpy()\n",
    "movies_id = np.array(movies_id).flatten()\n",
    "vocab = np.unique(movies_id)\n",
    "vocab_len = len(vocab)\n",
    "\n",
    "# print(vocab)\n",
    "print(vocab_len)\n",
    "print(movies_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoInfo(info_df):\n",
    "    return [\n",
    "        np.mean(info_df['temperature'].to_numpy()),\n",
    "        np.mean(info_df['brightness'].to_numpy()),\n",
    "        np.mean(info_df['colorfulness'].to_numpy()),\n",
    "        np.mean(info_df['energy'].to_numpy()),\n",
    "        np.mean(info_df['tempo'].to_numpy()),\n",
    "        np.mean(info_df['amplitude'].to_numpy()),\n",
    "        np.mean(info_df['spectral_rolloff'].to_numpy()),\n",
    "        np.mean(info_df['mfcc'].to_numpy())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}\n",
    "scenes_array = []\n",
    "del_array_name = []\n",
    "info_folder = \"/Volumes/Seagate/natasha-diploma/videoinfo\"\n",
    "for i in range(0, len(movies_id)):\n",
    "    try:\n",
    "        info_csv = info_folder + '/' + movies_id[i] + '.csv'\n",
    "        info_df =  pd.read_csv(info_csv, index_col=None, header=0)\n",
    "        info[movies_id[i]] = getVideoInfo(info_df.iloc[: , 4:])\n",
    "        scenes_array.append(info[movies_id[i]])\n",
    "    except:\n",
    "        del_array_name.append(movies_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_creater(arr):\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for i in range(len(arr)):\n",
    "        word2idx[arr[i]] = i\n",
    "        idx2word[i] = arr[i]\n",
    "\n",
    "    return word2idx, idx2word, len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, _ = vocab_creater(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArray(smth):\n",
    "    new = []\n",
    "    \n",
    "    for i in range(len(smth)):\n",
    "        new.append(word2idx[smth[i]])\n",
    "    \n",
    "    return new\n",
    "\n",
    "\n",
    "tokenized = toArray(movies_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010, 8)\n",
      "(2010,)\n",
      "[[ 1.    -1.    -1.    ...  1.    -1.     0.633]\n",
      " [-1.     0.455 -0.021 ...  0.25   0.957  0.364]\n",
      " [ 1.    -1.    -1.    ...  1.    -1.     0.633]\n",
      " ...\n",
      " [-1.     0.375 -0.405 ...  0.184  0.98  -0.463]\n",
      " [ 1.    -1.    -1.    ...  1.    -1.     0.633]\n",
      " [ 1.    -1.    -1.    ...  1.    -1.     0.633]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(scenes_array).shape)\n",
    "print(np.array(tokenized).shape)\n",
    "\n",
    "scenes_array = np.nan_to_num(scenes_array, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "scenes_array = normalize(scenes_array, axis=1, norm='l1')\n",
    "\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "scenes_array = np.around(scaler.fit_transform(scenes_array), 3)\n",
    "\n",
    "print(scenes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_size = 1\n",
    "id_embed_size = 8\n",
    "vocab_size = 366\n",
    "embedding_dim = 1024\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, id_size, id_embed_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.id_embedding = tf.keras.layers.Embedding(vocab_size, id_embed_size)\n",
    "        self.normalization = tf.keras.layers.BatchNormalization()\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size, activation=activations.relu)\n",
    "\n",
    "    def call(self, _input, states=None, return_state=False, training=False):\n",
    "        ids = self.id_embedding(_input[0])\n",
    "        features = self.normalization(_input[1])\n",
    "        x = self.concat([ids, features])\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "#     def train_step(self, data):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             y_pred = self(data, training=True)\n",
    "#             loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "#         trainable_vars = self.trainable_variables\n",
    "#         gradients = tape.gradient(loss, trainable_vars)\n",
    "#         self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "#         return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((), (8,)), types: (tf.int32, tf.float64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized = tokenized[:1400]\n",
    "test_tokenized = tokenized[1400:2000]\n",
    "\n",
    "train_scenes = scenes_array[:1400]\n",
    "test_scenes = scenes_array[1400:2000]\n",
    "\n",
    "ids_ds = tf.data.Dataset.from_tensor_slices(train_tokenized)\n",
    "features_ds = tf.data.Dataset.from_tensor_slices(train_scenes)\n",
    "\n",
    "ids_ds_test = tf.data.Dataset.from_tensor_slices(test_tokenized)\n",
    "features_ds_test = tf.data.Dataset.from_tensor_slices(test_scenes)\n",
    "\n",
    "ds_test = tf.data.Dataset.zip((ids_ds_test, features_ds_test))\n",
    "\n",
    "ds = tf.data.Dataset.zip((ids_ds, features_ds))\n",
    "seq_length = 10\n",
    "examples_per_epoch = len(tokenized) // (seq_length + 1)\n",
    "\n",
    "sequences = ds.batch(seq_length + 1, drop_remainder=True)\n",
    "ids_seq = ids_ds.batch(seq_length + 1, drop_remainder=True)\n",
    "features_seq = features_ds.batch(seq_length + 1, drop_remainder=True)\n",
    "sequences_test = ds_test.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 10), dtype=int32, numpy=\n",
      "array([[357, 141, 332,  90,   8,  64, 166,  33, 179,  19],\n",
      "       [365, 313,  41, 331,  26,  10, 109, 166,  61,  86],\n",
      "       [ 53, 104,  60, 141, 332, 272, 274, 228,  99, 162],\n",
      "       [ 60, 130, 284, 240,  28,  89,  40, 134, 173, 128],\n",
      "       [355,  65, 286, 169, 176, 257,  23, 276, 206, 296],\n",
      "       [154, 290,   7, 315, 145,  88, 269,  43, 127, 205],\n",
      "       [231,  53, 104,  60, 141, 332,  90, 354, 201,  76],\n",
      "       [267, 165, 224, 223, 327, 119, 156, 236, 235, 101],\n",
      "       [108, 347, 262,  60, 104, 298, 159, 231, 364, 222],\n",
      "       [141, 332,  90, 299, 192, 259, 161, 312,  85, 196],\n",
      "       [285, 279, 132, 225, 317, 310, 289, 320, 311,  96],\n",
      "       [159,  60, 141, 117,  67,  22,  44,  77, 325, 253],\n",
      "       [258, 271, 213, 143, 182, 156, 223, 224, 165, 119],\n",
      "       [194, 227, 319,  70, 324, 157, 118, 259, 192, 312],\n",
      "       [294, 280,  29, 338, 205, 277, 212, 254, 349,  35],\n",
      "       [ 38, 344, 125, 222,  58, 318, 188, 364, 126,  32],\n",
      "       [189,  62, 345, 190, 350, 343, 332,  90, 141,   8],\n",
      "       [254, 338, 205, 277,  14, 137, 128, 173, 155,  73],\n",
      "       [165, 267,  96,  20, 311,  50, 294, 148, 288, 212],\n",
      "       [182, 223, 224, 165, 119, 327, 138, 244, 103,  55],\n",
      "       [188,  57, 164, 201, 242,  76,   9,  66,  79, 238],\n",
      "       [110, 338, 205, 277, 114, 120, 307, 123, 142, 101],\n",
      "       [329, 233, 362, 139, 353, 356, 351,   0, 270, 265],\n",
      "       [352, 170,  77, 117, 325, 253,  44,  38,   6, 294],\n",
      "       [225, 317, 310, 289, 320,  48, 265, 270, 175, 342],\n",
      "       [332,  90,   8,  64, 166, 333, 108, 347,   5, 346],\n",
      "       [264, 158, 328, 210, 301, 364, 188, 231, 222,  53],\n",
      "       [274,  12,  92,   9,  76,  47,  72, 242, 201, 164],\n",
      "       [281, 251, 197, 326, 208, 297, 205, 212, 277, 200],\n",
      "       [347, 141, 332,  90,   8,  64, 166, 218, 333, 108],\n",
      "       [234, 113, 339, 207,  53, 104,  60, 141, 332,  90],\n",
      "       [108, 166, 218,  61,  55, 278, 171, 305, 103, 244]], dtype=int32)>, <tf.Tensor: shape=(32, 10, 8), dtype=float64, numpy=\n",
      "array([[[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.209, -0.664, -0.698, ...,  0.708, -0.217,  0.483],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   , -0.261, -0.217, ..., -0.336,  0.968, -0.984],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633]],\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.253, -0.687, -0.711, ...,  0.652, -0.262,  0.376],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633]],\n",
      "\n",
      "       [[ 0.035, -0.479, -0.351, ...,  0.725, -0.048,  0.693],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.455, -0.021, ...,  0.25 ,  0.957,  0.364],\n",
      "        ...,\n",
      "        [ 0.757, -0.856, -0.934, ...,  0.914, -0.759,  0.573],\n",
      "        [-1.   ,  0.524,  0.458, ...,  0.246,  0.934,  0.958],\n",
      "        [ 0.324, -0.833, -0.277, ...,  0.311, -0.363,  0.44 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.   ,  0.444,  0.022, ...,  0.418,  0.982, -0.141],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.209, -0.664, -0.698, ...,  0.708, -0.217,  0.483],\n",
      "        ...,\n",
      "        [ 0.249, -0.115, -0.676, ...,  0.752, -0.264,  0.501],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.074,  0.05 , ...,  0.002,  0.957,  0.236]],\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.327,  0.035, ...,  0.272,  0.967, -0.231],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.209, -0.664, -0.698, ...,  0.708, -0.217,  0.483],\n",
      "        [-1.   ,  0.143, -0.276, ...,  0.537,  0.984,  1.   ]],\n",
      "\n",
      "       [[-1.   ,  0.074,  0.05 , ...,  0.002,  0.957,  0.236],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.249, -0.115, -0.676, ...,  0.752, -0.264,  0.501],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.484,  0.306, ...,  0.145,  0.949, -0.768],\n",
      "        [ 0.992, -0.994, -0.991, ...,  0.995, -0.992,  0.631]]])>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (((32, 10), (32, 10, 8)), (32, 10)), types: ((tf.int32, tf.float64), tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def full_split_input_target(id_sequence, feature_sequence):\n",
    "    input_text = (id_sequence[:-1], feature_sequence[:-1])\n",
    "    target_text = (id_sequence[1:])\n",
    "    return input_text, target_text\n",
    "\n",
    "def split_input_target(seq):\n",
    "    input_text = seq[:-1]\n",
    "    target_text = seq[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "ds = sequences.map(full_split_input_target)\n",
    "ids_ds = ids_seq.map(split_input_target)\n",
    "features_ds = features_seq.map(split_input_target)\n",
    "ds_test = sequences_test.map(full_split_input_target)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "ds = (\n",
    "    ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "ids_ds = (\n",
    "    ids_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "features_ds = (\n",
    "    features_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "for _input, _output in ds_test.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).take(1):\n",
    "    print(_input)\n",
    "\n",
    "ds_test = (\n",
    "    ds_test\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 10), dtype=int32, numpy=\n",
      "array([[294, 280,  29, 338, 205, 277, 212, 254, 349,  35],\n",
      "       [231,  53, 104,  60, 141, 332,  90, 354, 201,  76],\n",
      "       [251,  15, 142, 285, 283, 279,  59, 225, 132, 317],\n",
      "       [147, 164,  45,  58,  57,  97, 199,   9, 201, 242],\n",
      "       [206, 330, 229, 314,  94, 274, 222,  27, 104, 159],\n",
      "       [335, 332, 141,  90,   8,  64, 166, 333, 108, 347],\n",
      "       [ 85, 312, 196, 259, 184, 161, 181, 162, 299, 192],\n",
      "       [ 60, 130, 284, 240,  28,  89,  40, 134, 173, 128],\n",
      "       [ 64, 166, 333,  10, 365, 331, 313,  41, 186, 275],\n",
      "       [141, 332,  90, 299, 192, 259, 161, 312,  85, 196],\n",
      "       [357, 141, 332,  90,   8,  64, 166,  33, 179,  19],\n",
      "       [175, 342, 110, 254, 338, 205,  63, 243, 121, 291],\n",
      "       [ 24,  92, 180,   1, 195, 256, 135,  47, 318,  26],\n",
      "       [110, 338, 205, 277, 114, 120, 307, 123, 142, 101],\n",
      "       [365, 313,  41, 331,  26,  10, 109, 166,  61,  86],\n",
      "       [225, 317, 310, 289, 320,  48, 265, 270, 175, 342],\n",
      "       [333,   8, 332, 141,  90,  64, 166, 108,   3,  30],\n",
      "       [347, 141, 332,  90,   8,  64, 166, 218, 333, 108],\n",
      "       [ 41, 186, 152, 101, 170, 169, 176, 286, 257,  23],\n",
      "       [329, 233, 362, 139, 353, 356, 351,   0, 270, 265],\n",
      "       [ 53, 104,  60, 141, 332, 272, 274, 228,  99, 162],\n",
      "       [234, 113, 339, 207,  53, 104,  60, 141, 332,  90],\n",
      "       [123, 363, 155, 137, 128, 173, 326, 297, 205, 212],\n",
      "       [285, 279, 132, 225, 310,  80, 293, 187, 245,  68],\n",
      "       [352, 170,  77, 117, 325, 253,  44,  38,   6, 294],\n",
      "       [154, 290,   7, 315, 145,  88, 269,  43, 127, 205],\n",
      "       [254, 338, 205, 277,  14, 137, 128, 173, 155,  73],\n",
      "       [242,  66,   9,  79, 238,  57, 109, 365, 331, 275],\n",
      "       [108, 166, 218,  61,  55, 278, 171, 305, 103, 244],\n",
      "       [258, 271, 213, 143, 182, 156, 223, 224, 165, 119],\n",
      "       [182, 223, 224, 165, 119, 327, 138, 244, 103,  55],\n",
      "       [355,  65, 286, 169, 176, 257,  23, 276, 206, 296]], dtype=int32)>, <tf.Tensor: shape=(32, 10, 8), dtype=float64, numpy=\n",
      "array([[[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.596,  0.118, ..., -0.057,  0.948,  0.334],\n",
      "        [-1.   ,  0.764,  0.078, ...,  0.415,  0.962,  0.797],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.312, -0.855, -0.907, ...,  0.656, -0.315,  0.141],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633]],\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.035, -0.479, -0.351, ...,  0.725, -0.048,  0.693],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.532, -0.272, ...,  0.496,  0.981,  0.393],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633]],\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   , -0.281, -0.217, ...,  0.218,  0.98 ,  0.238],\n",
      "        [-1.   ,  0.126,  0.083, ...,  0.484,  0.98 ,  0.483],\n",
      "        ...,\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 0.034, -0.268, -0.642, ...,  0.767, -0.041,  0.489]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.331,  0.285, ...,  0.365,  0.964,  0.522],\n",
      "        [-1.   ,  0.387, -0.221, ..., -0.496,  0.94 , -0.496],\n",
      "        ...,\n",
      "        [-1.   ,  0.32 ,  0.173, ...,  0.209,  0.957, -0.13 ],\n",
      "        [ 0.503, -0.846, -0.863, ...,  0.612, -0.522,  0.344],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633]],\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   , -0.24 , -0.15 , ...,  0.711,  0.997,  0.889],\n",
      "        [-1.   ,  0.32 ,  0.173, ...,  0.209,  0.957, -0.13 ],\n",
      "        ...,\n",
      "        [ 0.992, -0.994, -0.991, ...,  0.995, -0.992,  0.631],\n",
      "        [-1.   ,  0.484,  0.306, ...,  0.145,  0.949, -0.768],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633]],\n",
      "\n",
      "       [[ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        ...,\n",
      "        [ 0.189, -0.443, -0.666, ...,  0.561, -0.205,  0.3  ],\n",
      "        [ 1.   , -1.   , -1.   , ...,  1.   , -1.   ,  0.633],\n",
      "        [-1.   ,  0.284,  0.055, ...,  0.329,  0.972,  0.213]]])>) tf.Tensor(\n",
      "[[280  29 338 205 277 212 254 349  35 246]\n",
      " [ 53 104  60 141 332  90 354 201  76 164]\n",
      " [ 15 142 285 283 279  59 225 132 317 310]\n",
      " [164  45  58  57  97 199   9 201 242 219]\n",
      " [330 229 314  94 274 222  27 104 159  60]\n",
      " [332 141  90   8  64 166 333 108 347 261]\n",
      " [312 196 259 184 161 181 162 299 192 115]\n",
      " [130 284 240  28  89  40 134 173 128 137]\n",
      " [166 333  10 365 331 313  41 186 275 152]\n",
      " [332  90 299 192 259 161 312  85 196 184]\n",
      " [141 332  90   8  64 166  33 179  19  13]\n",
      " [342 110 254 338 205  63 243 121 291 263]\n",
      " [ 92 180   1 195 256 135  47 318  26 365]\n",
      " [338 205 277 114 120 307 123 142 101 211]\n",
      " [313  41 331  26  10 109 166  61  86  59]\n",
      " [317 310 289 320  48 265 270 175 342 110]\n",
      " [  8 332 141  90  64 166 108   3  30 198]\n",
      " [141 332  90   8  64 166 218 333 108 275]\n",
      " [186 152 101 170 169 176 286 257  23 276]\n",
      " [233 362 139 353 356 351   0 270 265 202]\n",
      " [104  60 141 332 272 274 228  99 162  27]\n",
      " [113 339 207  53 104  60 141 332  90   8]\n",
      " [363 155 137 128 173 326 297 205 212 277]\n",
      " [279 132 225 310  80 293 187 245  68 210]\n",
      " [170  77 117 325 253  44  38   6 294 281]\n",
      " [290   7 315 145  88 269  43 127 205 254]\n",
      " [338 205 277  14 137 128 173 155  73 363]\n",
      " [ 66   9  79 238  57 109 365 331 275 313]\n",
      " [166 218  61  55 278 171 305 103 244 156]\n",
      " [271 213 143 182 156 223 224 165 119 235]\n",
      " [223 224 165 119 327 138 244 103  55 255]\n",
      " [ 65 286 169 176 257  23 276 206 296 148]], shape=(32, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for _input, _output in ds_test.take(1):\n",
    "    print(_input, _output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((32, 10, 8), (32, 10, 8)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    id_size=id_size,\n",
    "    id_embed_size=id_embed_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 366) # (batch_size, sequence_length, vocab_size)\n",
      "[  6 278  73 290 330 341 274 281  50 284]\n"
     ]
    }
   ],
   "source": [
    "for _input, _output in ds.take(1):\n",
    "    example_batch_predictions = model(_input)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "    sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "    sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "\n",
    "    print(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  32        \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3201024   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  375150    \n",
      "=================================================================\n",
      "Total params: 3,579,134\n",
      "Trainable params: 3,579,118\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 5.9030 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 5.8727 - accuracy: 0.0344\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 5.8597 - accuracy: 0.0250\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 5.8182 - accuracy: 0.0562\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 5.7771 - accuracy: 0.0688\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 5.7392 - accuracy: 0.0625\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 5.7107 - accuracy: 0.0594\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 5.6168 - accuracy: 0.0625\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 5.5483 - accuracy: 0.0437\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 5.4308 - accuracy: 0.0406\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 5.2879 - accuracy: 0.0625\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 5.3430 - accuracy: 0.0500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5.1279 - accuracy: 0.0406\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.9770 - accuracy: 0.0688\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.9069 - accuracy: 0.0844\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.8729 - accuracy: 0.0594\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.8133 - accuracy: 0.0781\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4.6183 - accuracy: 0.0750\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 4.5897 - accuracy: 0.1187\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 4.6594 - accuracy: 0.1000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 4.5032 - accuracy: 0.0875\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 4.3650 - accuracy: 0.1187\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 4.3155 - accuracy: 0.1375\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 4.4035 - accuracy: 0.1156\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.2089 - accuracy: 0.1625\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 4.0080 - accuracy: 0.1937\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3.9986 - accuracy: 0.2219\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.9069 - accuracy: 0.2031\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.0222 - accuracy: 0.2094\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.8662 - accuracy: 0.2562\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 3.8026 - accuracy: 0.2250\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.5765 - accuracy: 0.2875\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3.7012 - accuracy: 0.3156\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3.7779 - accuracy: 0.2594\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.6643 - accuracy: 0.2875\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.4355 - accuracy: 0.3156\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 3.4323 - accuracy: 0.3688\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.5373 - accuracy: 0.2969\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.2808 - accuracy: 0.4031\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.2034 - accuracy: 0.4344\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.9881 - accuracy: 0.4406\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.0304 - accuracy: 0.4563\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.9980 - accuracy: 0.4781\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.9673 - accuracy: 0.4812\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.7869 - accuracy: 0.5437\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.8365 - accuracy: 0.5063\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.8016 - accuracy: 0.5469\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.6553 - accuracy: 0.5938\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.6975 - accuracy: 0.5437\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.7312 - accuracy: 0.5375\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.5060 - accuracy: 0.5750\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.4218 - accuracy: 0.6031\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.2621 - accuracy: 0.6375\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.3873 - accuracy: 0.6125\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.4269 - accuracy: 0.6000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.2164 - accuracy: 0.6281\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.3026 - accuracy: 0.6094\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.2792 - accuracy: 0.6156\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.1244 - accuracy: 0.6562\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0331 - accuracy: 0.6594\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0770 - accuracy: 0.6938\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0415 - accuracy: 0.6719\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.0419 - accuracy: 0.6656\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.9354 - accuracy: 0.6844\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.8157 - accuracy: 0.7188\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.2089 - accuracy: 0.6656\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.7959 - accuracy: 0.7156\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.7221 - accuracy: 0.7250\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.8757 - accuracy: 0.7094\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.7901 - accuracy: 0.7125\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.7600 - accuracy: 0.7219\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.4390 - accuracy: 0.7750\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.8117 - accuracy: 0.6969\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.8452 - accuracy: 0.7031\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.8444 - accuracy: 0.6875\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.6975 - accuracy: 0.7156\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.7756 - accuracy: 0.7063\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5657 - accuracy: 0.7281\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.7754 - accuracy: 0.7000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.7244 - accuracy: 0.7156\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.6571 - accuracy: 0.7156\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5676 - accuracy: 0.7563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5844 - accuracy: 0.7437\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.5953 - accuracy: 0.7281\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.3568 - accuracy: 0.7875\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4350 - accuracy: 0.7531\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.4167 - accuracy: 0.7656\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.5623 - accuracy: 0.7406\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.7340 - accuracy: 0.7344\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.6199 - accuracy: 0.7406\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.5299 - accuracy: 0.7344\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.6204 - accuracy: 0.7281\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.4531 - accuracy: 0.7312\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.4843 - accuracy: 0.7344\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.4964 - accuracy: 0.7594\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.5848 - accuracy: 0.7219\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.3660 - accuracy: 0.7812\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.2873 - accuracy: 0.7750\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.2567 - accuracy: 0.7750\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.3836 - accuracy: 0.7750\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.3899 - accuracy: 0.7750\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.3174 - accuracy: 0.7937\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.3873 - accuracy: 0.7750\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.3818 - accuracy: 0.7750\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.3753 - accuracy: 0.7625\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.2668 - accuracy: 0.7937\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.2937 - accuracy: 0.7688\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.3173 - accuracy: 0.7781\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.3101 - accuracy: 0.7812\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.4569 - accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.2238 - accuracy: 0.7969\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3351 - accuracy: 0.7531\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.2973 - accuracy: 0.7656\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.1592 - accuracy: 0.7906\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.2459 - accuracy: 0.7781\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.1802 - accuracy: 0.7812\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3122 - accuracy: 0.7531\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.1471 - accuracy: 0.7906\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.1504 - accuracy: 0.7812\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3396 - accuracy: 0.7531\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.3796 - accuracy: 0.7375\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3390 - accuracy: 0.7531\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.1631 - accuracy: 0.7844\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2459 - accuracy: 0.7781\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.2328 - accuracy: 0.7688\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.2043 - accuracy: 0.7812\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.1406 - accuracy: 0.7969\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.1392 - accuracy: 0.8062\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.3993 - accuracy: 0.7563\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.1592 - accuracy: 0.7906\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.3031 - accuracy: 0.7781\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2147 - accuracy: 0.7719\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.1306 - accuracy: 0.7969\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.2293 - accuracy: 0.7906\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.1275 - accuracy: 0.7937\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.2059 - accuracy: 0.7844\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.2241 - accuracy: 0.7781\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.1993 - accuracy: 0.7875\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.1118 - accuracy: 0.8094\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.0181 - accuracy: 0.8219\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.1142 - accuracy: 0.7906\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0327 - accuracy: 0.8094\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1336 - accuracy: 0.7844\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1188 - accuracy: 0.8031\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.1851 - accuracy: 0.7812\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.1835 - accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.1981 - accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9659 - accuracy: 0.8313\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0889 - accuracy: 0.8094\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.1041 - accuracy: 0.7969\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8916 - accuracy: 0.8500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.1057 - accuracy: 0.8062\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.1128 - accuracy: 0.8125\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.0021 - accuracy: 0.8281\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.0077 - accuracy: 0.8344\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.1019 - accuracy: 0.8125\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2121 - accuracy: 0.7844\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.0445 - accuracy: 0.8125\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1071 - accuracy: 0.8094\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.0253 - accuracy: 0.8250\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9143 - accuracy: 0.8375\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.0925 - accuracy: 0.8125\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8841 - accuracy: 0.8375\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8798 - accuracy: 0.8375\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9877 - accuracy: 0.8313\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1258 - accuracy: 0.7969\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9497 - accuracy: 0.8250\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.0154 - accuracy: 0.8250\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.0659 - accuracy: 0.8031\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9637 - accuracy: 0.8344\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.0923 - accuracy: 0.8094\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9422 - accuracy: 0.8406\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.0339 - accuracy: 0.8188\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.0781 - accuracy: 0.8281\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.1212 - accuracy: 0.8094\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9768 - accuracy: 0.8313\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9633 - accuracy: 0.8313\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9151 - accuracy: 0.8375\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9677 - accuracy: 0.8375\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.0621 - accuracy: 0.8219\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0177 - accuracy: 0.8219\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9001 - accuracy: 0.8469\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9284 - accuracy: 0.8344\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8997 - accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9177 - accuracy: 0.8313\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8868 - accuracy: 0.8438\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8654 - accuracy: 0.8594\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9622 - accuracy: 0.8469\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9708 - accuracy: 0.8438\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9167 - accuracy: 0.8344\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.0317 - accuracy: 0.8250\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9769 - accuracy: 0.8344\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8223 - accuracy: 0.8562\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9445 - accuracy: 0.8406\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9541 - accuracy: 0.8406\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7987 - accuracy: 0.8625\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8635 - accuracy: 0.8500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8654 - accuracy: 0.8625\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9510 - accuracy: 0.8438\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9563 - accuracy: 0.8469\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "history = model.fit(ds_test, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (((32, 10), (32, 10, 8)), (32, 10)), types: ((tf.int32, tf.float64), tf.int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9076 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.9075837135314941, 'accuracy': 0.8500000238418579}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test, batch_size=64, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
