{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>release_date</th>\n",
       "      <th>restrict</th>\n",
       "      <th>orig_title</th>\n",
       "      <th>kinopoisk_id</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>categories</th>\n",
       "      <th>genres</th>\n",
       "      <th>properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60432</td>\n",
       "      <td>Философия Фила</td>\n",
       "      <td>5816.0</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Phil</td>\n",
       "      <td>960568</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.86</td>\n",
       "      <td>Фил – стоматолог, страдающий от депрессии. Его...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Драмы,Зарубежные,Комедии}</td>\n",
       "      <td>{ \"Место действия\" : [\"США\"], \"Качества\" : [\"д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64219</td>\n",
       "      <td>Зубная фея</td>\n",
       "      <td>5123.0</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>1126022</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Старая женщина начинает рассказывать легенду о...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Зарубежные,Триллеры,Ужасы}</td>\n",
       "      <td>{ \"Место действия\" : [\"не определено\"], \"Качес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65407</td>\n",
       "      <td>Проснись</td>\n",
       "      <td>4667.0</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Wake Up</td>\n",
       "      <td>1069713</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Врач-психиатр исследует дневник девушки, котор...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Боевики,Зарубежные,Криминал,Триллеры,Ужасы}</td>\n",
       "      <td>{ \"Аудитория\" : [\"для взрослых\",\"для подготовл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75149</td>\n",
       "      <td>[4k] Адская кухня</td>\n",
       "      <td>6148.0</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>The Kitchen</td>\n",
       "      <td>1117988</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>Смотрите в 4К! Три жены ирландских гангстеров,...</td>\n",
       "      <td>{Фильмы}</td>\n",
       "      <td>{Боевики,Драмы,Зарубежные,Криминал,По комиксам}</td>\n",
       "      <td>{ \"Настроение\" : [\"захватывающие\",\"авантюрный\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75629</td>\n",
       "      <td>[4k] Покемон. Детектив Пикачу</td>\n",
       "      <td>6013.0</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Pokémon Detective Pikachu</td>\n",
       "      <td>994864</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.56</td>\n",
       "      <td>Смотрите в 4K! Элитный детектив Пикачу отправл...</td>\n",
       "      <td>{Для детей,Фильмы}</td>\n",
       "      <td>{Детективы,Зарубежные,Комедии,Семейные,Фильмы,...</td>\n",
       "      <td>{ \"Аудитория\" : [\"для детей 13-16 лет\",\"9 лет\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                          title  duration release_date  restrict  \\\n",
       "0  60432                 Философия Фила    5816.0   2019-04-05      18.0   \n",
       "1  64219                     Зубная фея    5123.0   2019-04-02      18.0   \n",
       "2  65407                       Проснись    4667.0   2019-01-19      16.0   \n",
       "3  75149              [4k] Адская кухня    6148.0   2019-08-09      16.0   \n",
       "4  75629  [4k] Покемон. Детектив Пикачу    6013.0   2019-05-02      12.0   \n",
       "\n",
       "                  orig_title  kinopoisk_id  imdb_rating  kinopoisk_rating  \\\n",
       "0                       Phil        960568          5.4              5.86   \n",
       "1                Tooth Fairy       1126022          2.2              0.00   \n",
       "2                    Wake Up       1069713          2.9              0.00   \n",
       "3                The Kitchen       1117988          5.5              5.50   \n",
       "4  Pokémon Detective Pikachu        994864          6.6              6.56   \n",
       "\n",
       "                                            synopsis          categories  \\\n",
       "0  Фил – стоматолог, страдающий от депрессии. Его...            {Фильмы}   \n",
       "1  Старая женщина начинает рассказывать легенду о...            {Фильмы}   \n",
       "2  Врач-психиатр исследует дневник девушки, котор...            {Фильмы}   \n",
       "3  Смотрите в 4К! Три жены ирландских гангстеров,...            {Фильмы}   \n",
       "4  Смотрите в 4K! Элитный детектив Пикачу отправл...  {Для детей,Фильмы}   \n",
       "\n",
       "                                              genres  \\\n",
       "0                         {Драмы,Зарубежные,Комедии}   \n",
       "1                        {Зарубежные,Триллеры,Ужасы}   \n",
       "2       {Боевики,Зарубежные,Криминал,Триллеры,Ужасы}   \n",
       "3    {Боевики,Драмы,Зарубежные,Криминал,По комиксам}   \n",
       "4  {Детективы,Зарубежные,Комедии,Семейные,Фильмы,...   \n",
       "\n",
       "                                          properties  \n",
       "0  { \"Место действия\" : [\"США\"], \"Качества\" : [\"д...  \n",
       "1  { \"Место действия\" : [\"не определено\"], \"Качес...  \n",
       "2  { \"Аудитория\" : [\"для взрослых\",\"для подготовл...  \n",
       "3  { \"Настроение\" : [\"захватывающие\",\"авантюрный\"...  \n",
       "4  { \"Аудитория\" : [\"для детей 13-16 лет\",\"9 лет\"...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>title_x</th>\n",
       "      <th>duration</th>\n",
       "      <th>release_date</th>\n",
       "      <th>restrict</th>\n",
       "      <th>orig_title</th>\n",
       "      <th>kinopoisk_id</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>emotions</th>\n",
       "      <th>Place of act</th>\n",
       "      <th>Qualities</th>\n",
       "      <th>Time of act</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Audience</th>\n",
       "      <th>Mood</th>\n",
       "      <th>Subgenre</th>\n",
       "      <th>About</th>\n",
       "      <th>Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Философия Фила</td>\n",
       "      <td>5816.0</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Phil</td>\n",
       "      <td>960568</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.86</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neutral': 0.5312193632125854, 'negative': 0....</td>\n",
       "      <td>['США']</td>\n",
       "      <td>['дебютный']</td>\n",
       "      <td>['21-й век', 'новейшее время']</td>\n",
       "      <td>['оригинального сценария']</td>\n",
       "      <td>['для молодёжи', 'для взрослых']</td>\n",
       "      <td>['грустный', 'депрессивный', 'трогательный']</td>\n",
       "      <td>['Драмы', 'Комедийные']</td>\n",
       "      <td>['преследования', 'самозванцы', 'расследование...</td>\n",
       "      <td>['развлекательные', 'психологический']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Зубная фея</td>\n",
       "      <td>5123.0</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Tooth Fairy</td>\n",
       "      <td>1126022</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>{'negative': 0.4688006341457367, 'skip': 0.392...</td>\n",
       "      <td>['не определено']</td>\n",
       "      <td>['зрелищные', 'жанровый', 'неожиданный финал']</td>\n",
       "      <td>['не определено']</td>\n",
       "      <td>['эпоса и легенд', 'оригинального сценария']</td>\n",
       "      <td>['для взрослых', 'для мужчин', 'для подготовле...</td>\n",
       "      <td>['трагичные', 'мрачные', 'шокирующие', 'захват...</td>\n",
       "      <td>['ужасы', 'триллер']</td>\n",
       "      <td>['преследования', 'страхи', 'дети', 'молодежь'...</td>\n",
       "      <td>['развлекательные']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Проснись</td>\n",
       "      <td>4667.0</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Wake Up</td>\n",
       "      <td>1069713</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>{'positive': 0.3140605390071869, 'negative': 0...</td>\n",
       "      <td>['не определено']</td>\n",
       "      <td>['жанровый', 'дебютный']</td>\n",
       "      <td>['новейшее время']</td>\n",
       "      <td>['оригинального сценария']</td>\n",
       "      <td>['для взрослых', 'для подготовленного зрителя'...</td>\n",
       "      <td>['захватывающие', 'жестокие', 'напряженные', '...</td>\n",
       "      <td>['Драмы', 'Боевики', 'триллер']</td>\n",
       "      <td>['психотерапевты', 'кровь', 'тайна смерти', 'п...</td>\n",
       "      <td>['психологический', 'развлекательные']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[4k] Адская кухня</td>\n",
       "      <td>6148.0</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>The Kitchen</td>\n",
       "      <td>1117988</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neutral': 0.4765896201133728, 'negative': 0....</td>\n",
       "      <td>['большой город', 'США']</td>\n",
       "      <td>['жанровый', 'остросюжетные']</td>\n",
       "      <td>['20-й век']</td>\n",
       "      <td>['комиксов']</td>\n",
       "      <td>['для мужчин', 'для женщин', 'для взрослых']</td>\n",
       "      <td>['захватывающие', 'авантюрный', 'жестокие', 'н...</td>\n",
       "      <td>['Боевики', 'Драмы', 'криминальные']</td>\n",
       "      <td>['враги или вражда', 'женщины', 'антигерои', '...</td>\n",
       "      <td>['авантюрные', 'гангстерская']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>[4k] Покемон. Детектив Пикачу</td>\n",
       "      <td>6013.0</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Pokémon Detective Pikachu</td>\n",
       "      <td>994864</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.56</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neutral': 0.4532718360424042, 'negative': 0....</td>\n",
       "      <td>['вымышленная страна (город)', 'большой город']</td>\n",
       "      <td>['частично анимационный', 'зрелищные', 'кассов...</td>\n",
       "      <td>['21-й век']</td>\n",
       "      <td>['оригинального сценария', 'сериалов']</td>\n",
       "      <td>['для детей 13-16 лет', '9 лет', '8 лет', '7-1...</td>\n",
       "      <td>['авантюрный', 'захватывающие', 'динамичный', ...</td>\n",
       "      <td>['детские', 'Приключенческие', 'Фантастические...</td>\n",
       "      <td>['притяжение противоположностей', 'риск', 'пре...</td>\n",
       "      <td>['развлекательные', 'образовательный']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                        title_x  duration  \\\n",
       "0           0             0                 Философия Фила    5816.0   \n",
       "1           1             4                     Зубная фея    5123.0   \n",
       "2           2             5                       Проснись    4667.0   \n",
       "3           3             6              [4k] Адская кухня    6148.0   \n",
       "4           4             7  [4k] Покемон. Детектив Пикачу    6013.0   \n",
       "\n",
       "  release_date  restrict                 orig_title  kinopoisk_id  \\\n",
       "0   2019-04-05      18.0                       Phil        960568   \n",
       "1   2019-04-02      18.0                Tooth Fairy       1126022   \n",
       "2   2019-01-19      16.0                    Wake Up       1069713   \n",
       "3   2019-08-09      16.0                The Kitchen       1117988   \n",
       "4   2019-05-02      12.0  Pokémon Detective Pikachu        994864   \n",
       "\n",
       "   imdb_rating  kinopoisk_rating  ...  \\\n",
       "0          5.4              5.86  ...   \n",
       "1          2.2              0.00  ...   \n",
       "2          2.9              0.00  ...   \n",
       "3          5.5              5.50  ...   \n",
       "4          6.6              6.56  ...   \n",
       "\n",
       "                                            emotions  \\\n",
       "0  {'neutral': 0.5312193632125854, 'negative': 0....   \n",
       "1  {'negative': 0.4688006341457367, 'skip': 0.392...   \n",
       "2  {'positive': 0.3140605390071869, 'negative': 0...   \n",
       "3  {'neutral': 0.4765896201133728, 'negative': 0....   \n",
       "4  {'neutral': 0.4532718360424042, 'negative': 0....   \n",
       "\n",
       "                                      Place of act  \\\n",
       "0                                          ['США']   \n",
       "1                                ['не определено']   \n",
       "2                                ['не определено']   \n",
       "3                         ['большой город', 'США']   \n",
       "4  ['вымышленная страна (город)', 'большой город']   \n",
       "\n",
       "                                           Qualities  \\\n",
       "0                                       ['дебютный']   \n",
       "1     ['зрелищные', 'жанровый', 'неожиданный финал']   \n",
       "2                           ['жанровый', 'дебютный']   \n",
       "3                      ['жанровый', 'остросюжетные']   \n",
       "4  ['частично анимационный', 'зрелищные', 'кассов...   \n",
       "\n",
       "                      Time of act  \\\n",
       "0  ['21-й век', 'новейшее время']   \n",
       "1               ['не определено']   \n",
       "2              ['новейшее время']   \n",
       "3                    ['20-й век']   \n",
       "4                    ['21-й век']   \n",
       "\n",
       "                                       Based on  \\\n",
       "0                    ['оригинального сценария']   \n",
       "1  ['эпоса и легенд', 'оригинального сценария']   \n",
       "2                    ['оригинального сценария']   \n",
       "3                                  ['комиксов']   \n",
       "4        ['оригинального сценария', 'сериалов']   \n",
       "\n",
       "                                            Audience  \\\n",
       "0                   ['для молодёжи', 'для взрослых']   \n",
       "1  ['для взрослых', 'для мужчин', 'для подготовле...   \n",
       "2  ['для взрослых', 'для подготовленного зрителя'...   \n",
       "3       ['для мужчин', 'для женщин', 'для взрослых']   \n",
       "4  ['для детей 13-16 лет', '9 лет', '8 лет', '7-1...   \n",
       "\n",
       "                                                Mood  \\\n",
       "0       ['грустный', 'депрессивный', 'трогательный']   \n",
       "1  ['трагичные', 'мрачные', 'шокирующие', 'захват...   \n",
       "2  ['захватывающие', 'жестокие', 'напряженные', '...   \n",
       "3  ['захватывающие', 'авантюрный', 'жестокие', 'н...   \n",
       "4  ['авантюрный', 'захватывающие', 'динамичный', ...   \n",
       "\n",
       "                                            Subgenre  \\\n",
       "0                            ['Драмы', 'Комедийные']   \n",
       "1                               ['ужасы', 'триллер']   \n",
       "2                    ['Драмы', 'Боевики', 'триллер']   \n",
       "3               ['Боевики', 'Драмы', 'криминальные']   \n",
       "4  ['детские', 'Приключенческие', 'Фантастические...   \n",
       "\n",
       "                                               About  \\\n",
       "0  ['преследования', 'самозванцы', 'расследование...   \n",
       "1  ['преследования', 'страхи', 'дети', 'молодежь'...   \n",
       "2  ['психотерапевты', 'кровь', 'тайна смерти', 'п...   \n",
       "3  ['враги или вражда', 'женщины', 'антигерои', '...   \n",
       "4  ['притяжение противоположностей', 'риск', 'пре...   \n",
       "\n",
       "                                    Theme  \n",
       "0  ['развлекательные', 'психологический']  \n",
       "1                     ['развлекательные']  \n",
       "2  ['психологический', 'развлекательные']  \n",
       "3          ['авантюрные', 'гангстерская']  \n",
       "4  ['развлекательные', 'образовательный']  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60432</td>\n",
       "      <td>174457</td>\n",
       "      <td>184174</td>\n",
       "      <td>111847</td>\n",
       "      <td>172257</td>\n",
       "      <td>227812</td>\n",
       "      <td>250885</td>\n",
       "      <td>174558</td>\n",
       "      <td>212559</td>\n",
       "      <td>214967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65407</td>\n",
       "      <td>225043</td>\n",
       "      <td>138191</td>\n",
       "      <td>177902</td>\n",
       "      <td>176620</td>\n",
       "      <td>225371</td>\n",
       "      <td>190349</td>\n",
       "      <td>147590</td>\n",
       "      <td>181198</td>\n",
       "      <td>138245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75149</td>\n",
       "      <td>60432</td>\n",
       "      <td>133587</td>\n",
       "      <td>148584</td>\n",
       "      <td>186787</td>\n",
       "      <td>222725</td>\n",
       "      <td>212087</td>\n",
       "      <td>174369</td>\n",
       "      <td>423155</td>\n",
       "      <td>431690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75629</td>\n",
       "      <td>205372</td>\n",
       "      <td>186058</td>\n",
       "      <td>171392</td>\n",
       "      <td>160160</td>\n",
       "      <td>184174</td>\n",
       "      <td>172257</td>\n",
       "      <td>75630</td>\n",
       "      <td>226747</td>\n",
       "      <td>212559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75630</td>\n",
       "      <td>172257</td>\n",
       "      <td>219611</td>\n",
       "      <td>211554</td>\n",
       "      <td>248722</td>\n",
       "      <td>250977</td>\n",
       "      <td>216926</td>\n",
       "      <td>190967</td>\n",
       "      <td>415428</td>\n",
       "      <td>419254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8  \\\n",
       "0  60432  174457  184174  111847  172257  227812  250885  174558  212559   \n",
       "1  65407  225043  138191  177902  176620  225371  190349  147590  181198   \n",
       "2  75149   60432  133587  148584  186787  222725  212087  174369  423155   \n",
       "3  75629  205372  186058  171392  160160  184174  172257   75630  226747   \n",
       "4  75630  172257  219611  211554  248722  250977  216926  190967  415428   \n",
       "\n",
       "        9  \n",
       "0  214967  \n",
       "1  138245  \n",
       "2  431690  \n",
       "3  212559  \n",
       "4  419254  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "film_csv = \"/Volumes/Seagate/natasha-diploma/content_data.csv\"\n",
    "trailers_csv = \"/Volumes/Seagate/natasha-diploma/trailers.csv\"\n",
    "sessions_csv = \"/Volumes/Seagate/natasha-diploma/sessions.csv\"\n",
    "\n",
    "films = pd.read_csv(film_csv, index_col=None, header=0)\n",
    "display(films.head())\n",
    "\n",
    "trailers_meta = pd.read_csv(trailers_csv, index_col=None, header=0)\n",
    "display(trailers_meta.head())\n",
    "\n",
    "\n",
    "\n",
    "sessions = pd.read_csv(sessions_csv, index_col=None, header=0)\n",
    "sessions.drop(sessions.columns[sessions.columns.str.contains('Unnamed',case = False)],axis = 1, inplace = True)\n",
    "        \n",
    "display(sessions.head())\n",
    "\n",
    "sess = sessions.to_numpy().tolist()\n",
    "\n",
    "in_sess = []\n",
    "out_sess = []\n",
    "for i in range(len(sess)):\n",
    "    in_sess.append(sess[i][:5])\n",
    "    out_sess.append(sess[i][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l): return flatten(l[0]) + (flatten(l[1:]) if len(l) > 1 else []) if type(l) is list else [l]\n",
    "\n",
    "def vocab_creater(arr, add_num):\n",
    "    json_arr = []\n",
    "    for i in range(len(arr)):\n",
    "        js = json.loads(arr[i].replace('\\'', '\\\"'))\n",
    "        json_arr.append(js)\n",
    "    flat_arr = flatten(json_arr)\n",
    "    dic = list(dict.fromkeys(flat_arr))\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for i in range(len(dic)):\n",
    "        word2idx[dic[i]] = i + add_num\n",
    "        idx2word[i + add_num] = dic[i]\n",
    "\n",
    "    return word2idx, idx2word, len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailers_meta_array = []\n",
    "\n",
    "time_of_act = trailers_meta['Time of act'].values\n",
    "place_of_act = trailers_meta['Place of act'].to_numpy()\n",
    "qualities = trailers_meta['Qualities'].to_numpy()\n",
    "based_on = trailers_meta['Based on'].to_numpy()\n",
    "content_id = trailers_meta['content_id'].values\n",
    "audience = trailers_meta['Audience'].to_numpy()\n",
    "mood = trailers_meta['Mood'].to_numpy()\n",
    "subgenre = trailers_meta['Subgenre'].to_numpy()\n",
    "about = trailers_meta['About'].to_numpy()\n",
    "theme = trailers_meta['Theme'].to_numpy()\n",
    "\n",
    "add_num = 0\n",
    "time_vocab = vocab_creater(time_of_act, add_num)\n",
    "add_num += time_vocab[2] + 10\n",
    "place_vocab = vocab_creater(place_of_act, add_num)\n",
    "add_num += place_vocab[2]\n",
    "qua_vocab = vocab_creater(qualities, add_num)\n",
    "add_num += qua_vocab[2]\n",
    "based_vocab = vocab_creater(based_on, add_num)\n",
    "add_num += based_vocab[2]\n",
    "audi_vocab = vocab_creater(audience, add_num)\n",
    "add_num += audi_vocab[2]\n",
    "mood_vocab = vocab_creater(mood, add_num)\n",
    "add_num += mood_vocab[2]\n",
    "subgenr_vocab = vocab_creater(subgenre, add_num)\n",
    "add_num += subgenr_vocab[2]\n",
    "about_vocab = vocab_creater(about, add_num)\n",
    "add_num += about_vocab[2]\n",
    "theme_vocab = vocab_creater(theme, add_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_arr(arr, vocab):\n",
    "    json_arr = []\n",
    "    for i in range(len(arr)):\n",
    "        js = json.loads(arr[i].replace('\\'', '\\\"'))\n",
    "        json_arr.append(js)\n",
    "    vocabs_arr = []\n",
    "    for i in range(len(json_arr)):\n",
    "        j_vocabs_arr = []\n",
    "        for j in range(len(json_arr[i])):\n",
    "            value = json_arr[i][j]\n",
    "            j_vocabs_arr.append(vocab[value])\n",
    "        vocabs_arr.append(j_vocabs_arr)\n",
    "            \n",
    "    return vocabs_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_time = tokenize_arr(time_of_act, time_vocab[0])\n",
    "tok_place = tokenize_arr(place_of_act, place_vocab[0])\n",
    "tok_quality = tokenize_arr(qualities, qua_vocab[0])\n",
    "tok_based_on = tokenize_arr(based_on, based_vocab[0])\n",
    "tok_audience = tokenize_arr(audience, audi_vocab[0])\n",
    "tok_mood = tokenize_arr(mood, mood_vocab[0])\n",
    "tok_subgenre = tokenize_arr(subgenre, subgenr_vocab[0])\n",
    "tok_about = tokenize_arr(about, about_vocab[0])\n",
    "tok_theme = tokenize_arr(theme, theme_vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailers_meta_preprocessed = []\n",
    "in_sess_preprocessed = []\n",
    "out_sess_preprocessed = []\n",
    "for i in range(len(tok_time)):\n",
    "    trailers_meta_preprocessed.append([\n",
    "#         content_id[i],\n",
    "        tok_time[i],\n",
    "        tok_place[i],\n",
    "        tok_quality[i],\n",
    "        tok_based_on[i],\n",
    "        tok_audience[i],\n",
    "        tok_mood[i],\n",
    "        tok_subgenre[i],\n",
    "        tok_about[i],\n",
    "        tok_theme[i]\n",
    "    ])\n",
    "\n",
    "    \n",
    "for i in range(len(in_sess)):\n",
    "    in_sess_preprocessed_j = []\n",
    "    for j in range(len(in_sess[i])):\n",
    "        ind = content_id.tolist().index(in_sess[i][j])\n",
    "        if ind:\n",
    "            in_sess_preprocessed_j.append([\n",
    "#                 content_id[ind],\n",
    "                tok_time[ind][0],\n",
    "                tok_place[ind][0],\n",
    "                tok_quality[ind][0],\n",
    "                tok_based_on[ind][0],\n",
    "                tok_audience[ind][0],\n",
    "                tok_mood[ind][0],\n",
    "                tok_subgenre[ind][0],\n",
    "                tok_about[ind][0],\n",
    "                tok_theme[ind][0]\n",
    "            ])\n",
    "    in_sess_preprocessed.append(in_sess_preprocessed_j)\n",
    "    \n",
    "for i in range(len(out_sess)):\n",
    "    out_sess_preprocessed_j = []\n",
    "    for j in range(len(out_sess[i])):\n",
    "        ind = content_id.tolist().index(out_sess[i][j])\n",
    "        if ind:\n",
    "            out_sess_preprocessed_j.append([\n",
    "#                 content_id[ind],\n",
    "                tok_time[ind][0],\n",
    "                tok_place[ind][0],\n",
    "                tok_quality[ind][0],\n",
    "                tok_based_on[ind][0],\n",
    "                tok_audience[ind][0],\n",
    "                tok_mood[ind][0],\n",
    "                tok_subgenre[ind][0],\n",
    "                tok_about[ind][0],\n",
    "                tok_theme[ind][0]\n",
    "            ])\n",
    "    out_sess_preprocessed.append(out_sess_preprocessed_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробовать с 3d массивом, надо дополнить недостающее нулями\n",
    "x = []\n",
    "for i in range(len(in_sess_preprocessed)):\n",
    "    for j in range(len(in_sess_preprocessed[i])):\n",
    "        x.append(in_sess_preprocessed[i][j])\n",
    "        \n",
    "y = []\n",
    "for i in range(len(out_sess_preprocessed)):\n",
    "    for j in range(len(out_sess_preprocessed[i])):\n",
    "        y.append(out_sess_preprocessed[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = 500000\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(249, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2,\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 9)\n",
      "(249, 9)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(x).shape)\n",
    "print(np.array(y[:-2]).shape)\n",
    "x = np.array(x).astype(np.float)\n",
    "y = np.array(y).astype(np.float)\n",
    "x_train = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
    "y_train = np.reshape(y[:-2], (y[:-2].shape[0], y[:-2].shape[1], 1))\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "# history = model.fit(np.asarray(x_train)[:200], np.asarray(y_train)[:200], epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(np.asarray(x_train)[200:], np.asarray(y_train)[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x) # вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(array, max_len, max_h):\n",
    "    new_arr = []\n",
    "    for i in range(max_len):\n",
    "        new_arr_j = []\n",
    "        if (i < np.array(array).shape[0]):\n",
    "            for j in range(max_h):\n",
    "                if j < np.array(array).shape[1]:\n",
    "                    new_arr_j.append(array[i][j])\n",
    "                else:\n",
    "                    new_arr_j.append(0)\n",
    "        else:\n",
    "            for j in range(max_h):\n",
    "                 new_arr_j.append(0)\n",
    "        new_arr.append(new_arr_j)\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nutochkina/PycharmProjects/diploma/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/nutochkina/PycharmProjects/diploma/venv/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/nutochkina/PycharmProjects/diploma/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/nutochkina/PycharmProjects/diploma/venv/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 396\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_array = []\n",
    "min_len = 100\n",
    "max_len = 0\n",
    "del_array_id = []\n",
    "info_folder = \"/Volumes/Seagate/natasha-diploma/videoinfo\"\n",
    "for i in range(0, len(trailers_meta)):\n",
    "    name = trailers_meta.iloc[i]['trailers_name']\n",
    "    content_id = trailers_meta.iloc[i]['content_id']\n",
    "    try:\n",
    "        info_csv = info_folder + '/' + name + '.csv'\n",
    "        info_df =  pd.read_csv(info_csv, index_col=None, header=0)\n",
    "        info_df = info_df.iloc[: , 3:]\n",
    "        np_info_df = info_df.to_numpy()\n",
    "        new_arr = []\n",
    "        for i in range(len(np_info_df)):\n",
    "            new_arr_j = []\n",
    "            for j in range(len(np_info_df[i])):\n",
    "                if isinstance(np_info_df[i][j], int) or isinstance(np_info_df[i][j], float):\n",
    "                    new_arr_j.append(np_info_df[i][j])\n",
    "                else:\n",
    "                    nums = [int(s) for s in np_info_df[i][j].split() if s.isdigit()]\n",
    "                    new_arr_j.append(float(np.mean(nums)))\n",
    "            new_arr.append(new_arr_j)\n",
    "            \n",
    "        info_array.append(preprocessing.normalize(new_arr))        \n",
    "#         print(info_array[i])\n",
    "        if len(info_array[i]) < min_len:\n",
    "            min_len = len(info_array[i])\n",
    "            min_name = name\n",
    "        if len(info_array[i]) > max_len:\n",
    "            max_len = len(info_array[i])\n",
    "            max_name = name\n",
    "    except:\n",
    "        del_array_id.append(content_id)\n",
    "        \n",
    "print(min_len, max_len)\n",
    "padded = []\n",
    "for i in range (len(info_array)):\n",
    "    print(i)\n",
    "    padded.append(pad(info_array[i], max_len, 23))\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 396, 23)\n"
     ]
    }
   ],
   "source": [
    "shape = np.array(padded).shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoder_input = Input(shape=(shape[1], shape[2]))\n",
    "encoder_LSTM1 = LSTM(shape[0], return_sequences=True, dropout=0.2)\n",
    "encoder_outputs = encoder_LSTM1(encoder_input)\n",
    "encoder_LSTM2 = LSTM(249, return_state=True)\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM2(encoder_outputs)\n",
    "encoder_states = [encoder_h, encoder_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "decoder_input = Input(shape=(9, 1))\n",
    "decoder_LSTM1 = LSTM(249, return_sequences=True, dropout=0.2)\n",
    "decoder_output = decoder_LSTM1(decoder_input, initial_state=encoder_states)\n",
    "decoder_LSTM2 = LSTM(128, return_sequences=True, return_state=True)\n",
    "decoder_output, _, _ = decoder_LSTM2(decoder_output)\n",
    "decoder_dense = Dense(912, activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "x = np.asarray(x_train)[:200].tolist()\n",
    "y = np.asarray(y_train)[:200].tolist()\n",
    "\n",
    "for i in range(709):\n",
    "    x.append(np.asarray(np.zeros((9, 1))))\n",
    "    y.append(np.asarray(np.zeros((9, 1))))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[np.asarray(padded), np.asarray(x)], y=np.asarray(y), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(padded[888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(x_train)[200:].tolist()\n",
    "y = np.asarray(y_train)[200:].tolist()\n",
    "\n",
    "for i in range(909-49):\n",
    "    x.append(np.asarray(np.zeros((9, 1))))\n",
    "    y.append(np.asarray(np.zeros((9, 1))))\n",
    "    \n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([np.asarray(padded), np.asarray(x)], np.asarray(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict([np.asarray(padded), np.asarray(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
